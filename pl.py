import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="üìù Revisor de PrensaLibre",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üìù Revisor de Ortograf√≠a y Gram√°tica para PrensaLibre.com")

# Obtener la clave de API desde los secretos de Streamlit
API_KEY = st.secrets["api"]["key"]
API_URL = "https://api.x.ai/v1/chat/completions"

# Definir los selectores en un diccionario para facilitar futuras actualizaciones
selectores = {
    'contenido_articulo': {'tag': 'div', 'class': 'ArticleBody'},  # Selector del contenido del art√≠culo
    # Puedes a√±adir m√°s selectores si es necesario
}

def es_url_prensalibre(url):
    """
    Verifica si la URL pertenece a PrensaLibre.com
    """
    try:
        parsed_url = urlparse(url)
        return "prensalibre.com" in parsed_url.netloc
    except:
        return False

def obtener_contenido_articulo(url):
    """
    Extrae el contenido textual de un art√≠culo dado su URL.
    """
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            st.error(f"No se pudo acceder a la URL proporcionada. (Estado: {response.status_code})")
            return None

        soup = BeautifulSoup(response.text, 'html.parser')

        # Extraer el contenido del art√≠culo usando el selector definido
        contenido_articulo = soup.find(selectores['contenido_articulo']['tag'], class_=selectores['contenido_articulo']['class'])
        if not contenido_articulo:
            st.error("‚ö†Ô∏è No se pudo encontrar el contenido del art√≠culo con los selectores especificados.")
            # Opcional: Mostrar HTML para depuraci√≥n
            if st.checkbox("üìÑ Mostrar HTML para depuraci√≥n"):
                st.code(soup.prettify(), language='html')
            return None

        # Extraer todos los p√°rrafos del contenido del art√≠culo
        parrafos = contenido_articulo.find_all('p')
        texto_completo = "\n".join([p.get_text() for p in parrafos])

        if not texto_completo.strip():
            st.warning("‚ö†Ô∏è El art√≠culo no contiene texto para analizar.")
            return None

        return texto_completo

    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Error en la solicitud HTTP: {e}")
        return None
    except Exception as e:
        st.error(f"‚ùå Error al procesar el contenido del art√≠culo: {e}")
        return None

def analizar_texto(texto):
    """
    Env√≠a el texto a la API de X para su an√°lisis de ortograf√≠a y gram√°tica.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    data = {
        "messages": [
            {
                "role": "system",
                "content": "You are a grammar and spelling assistant."
            },
            {
                "role": "user",
                "content": f"Revisa el siguiente texto en espa√±ol y proporciona un informe detallado de los errores ortogr√°ficos y gramaticales, as√≠ como sugerencias de mejora:\n\n{texto}"
            }
        ],
        "model": "grok-beta",          # Modelo especificado
        "stream": False,               # Streaming deshabilitado
        "temperature": 0               # Temperatura configurada a 0
    }
    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=60)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            st.error(f"‚ùå Error en la API: {response.status_code} - {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Error en la solicitud a la API: {e}")
        return None
    except Exception as e:
        st.error(f"‚ùå Error al procesar la respuesta de la API: {e}")
        return None

# Interfaz de usuario
st.sidebar.header("üìÇ Analizar Art√≠culo")
url_usuario = st.sidebar.text_input("üîó Pega la URL de un art√≠culo de PrensaLibre.com", "")

if st.sidebar.button("üîç Analizar Art√≠culo"):
    if not url_usuario:
        st.sidebar.warning("‚ö†Ô∏è Por favor, pega una URL para analizar.")
    elif not es_url_prensalibre(url_usuario):
        st.sidebar.error("‚ùå La URL proporcionada no pertenece a PrensaLibre.com.")
    else:
        with st.spinner("üì• Obteniendo contenido del art√≠culo..."):
            contenido = obtener_contenido_articulo(url_usuario)
        if contenido:
            st.subheader("üìë Contenido del Art√≠culo")
            st.text_area("üìù Texto a analizar", contenido, height=300)

            if st.button("‚úÖ Revisar Ortograf√≠a y Gram√°tica"):
                with st.spinner("üîÑ Analizando texto..."):
                    informe = analizar_texto(contenido)
                if informe:
                    st.subheader("üìÑ Informe de Revisi√≥n")
                    st.write(informe)
