import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Revisor de PrensaLibre",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üìù Revisor de Ortograf√≠a y Gram√°tica para PrensaLibre.com")

# Obtener la clave de API desde los secretos de Streamlit
API_KEY = st.secrets["api"]["key"]
API_URL = "https://api.x.ai/v1/chat/completions"

# Mapeo de secciones a sus URLs correspondientes
secciones_urls = {
    "Nacional": "https://www.prensalibre.com/nacional/",
    "Internacional": "https://www.prensalibre.com/internacional/",
    "Econom√≠a": "https://www.prensalibre.com/economia/",
    "Deportes": "https://www.prensalibre.com/deportes/",
    "Cultura": "https://www.prensalibre.com/cultura/",
    "Opini√≥n": "https://www.prensalibre.com/opinion/",
    "Tecnolog√≠a": "https://www.prensalibre.com/tecnologia/",
    "Salud": "https://www.prensalibre.com/salud/",
    "Educaci√≥n": "https://www.prensalibre.com/educacion/",
    "Otros": "https://www.prensalibre.com/"
}

# Definir los selectores en un diccionario para facilitar futuras actualizaciones
selectores = {
    'lista_articulos': {'tag': 'h2', 'class': 'ArticleListing__title'},  # Selector de titulares
    'contenido_articulo': {'tag': 'div', 'class': 'ArticleBody'},        # Selector del contenido del art√≠culo
}

# Funci√≥n para obtener el contenido de la secci√≥n
def obtener_contenido(seccion):
    url = secciones_urls.get(seccion)
    if not url:
        st.error(f"La secci√≥n '{seccion}' no tiene una URL mapeada.")
        return None

    st.write(f"üîç Accediendo a la URL: {url}")  # Mensaje de depuraci√≥n

    try:
        response = requests.get(url)
        if response.status_code != 200:
            st.error(f"No se pudo obtener el contenido de la secci√≥n {seccion}. (Estado: {response.status_code})")
            return None
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extraer art√≠culos usando los selectores definidos
        articulos = soup.find_all(selectores['lista_articulos']['tag'], class_=selectores['lista_articulos']['class'])

        if not articulos:
            st.warning("‚ö†Ô∏è No se encontraron art√≠culos con el selector especificado. Verifica los selectores en el c√≥digo.")
            # Mostrar HTML para depuraci√≥n
            if st.checkbox("Mostrar HTML de la secci√≥n para depuraci√≥n"):
                st.code(soup.prettify(), language='html')
            return None

        texto_completo = ""
        enlaces_encontrados = []  # Para depuraci√≥n

        for articulo in articulos[:5]:  # Limitar a los primeros 5 art√≠culos para ejemplo
            enlace_tag = articulo.find('a')
            if enlace_tag and 'href' in enlace_tag.attrs:
                enlace = enlace_tag['href']
                enlace_completo = urljoin(url, enlace)
                enlaces_encontrados.append(enlace_completo)

                resp_art = requests.get(enlace_completo)
                if resp_art.status_code == 200:
                    soup_art = BeautifulSoup(resp_art.text, 'html.parser')
                    # Ajustar el selector del contenido del art√≠culo
                    contenido_articulo = soup_art.find(selectores['contenido_articulo']['tag'], class_=selectores['contenido_articulo']['class'])
                    if contenido_articulo:
                        parrafos = contenido_articulo.find_all('p')
                        for p in parrafos:
                            texto_completo += p.get_text() + "\n"
                    else:
                        st.warning(f"‚ö†Ô∏è No se pudo extraer el contenido del art√≠culo: {enlace_completo}")
                else:
                    st.warning(f"‚ö†Ô∏è No se pudo acceder al art√≠culo: {enlace_completo} (Estado: {resp_art.status_code})")
            else:
                st.warning("‚ö†Ô∏è No se encontr√≥ el enlace en el art√≠culo.")

        # Opcional: Mostrar enlaces extra√≠dos
        if st.checkbox("üîó Mostrar enlaces extra√≠dos"):
            st.write("**Enlaces encontrados:**")
            for enlace in enlaces_encontrados:
                st.markdown(f"- [{enlace}]({enlace})")

        if not texto_completo:
            st.warning("‚ö†Ô∏è No se encontr√≥ contenido para analizar.")
        return texto_completo
    except Exception as e:
        st.error(f"‚ùå Error al obtener el contenido: {e}")
        return None

# Funci√≥n para analizar el texto usando la API de X
def analizar_texto(texto):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    data = {
        "messages": [
            {
                "role": "system",
                "content": "You are a test assistant."
            },
            {
                "role": "user",
                "content": f"Revisa el siguiente texto en espa√±ol y proporciona un informe detallado de los errores ortogr√°ficos y gramaticales, as√≠ como sugerencias de mejora:\n\n{texto}"
            }
        ],
        "model": "grok-beta",          # Modelo especificado
        "stream": False,               # Streaming deshabilitado
        "temperature": 0               # Temperatura configurada a 0
    }
    try:
        response = requests.post(API_URL, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            st.error(f"‚ùå Error en la API: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"‚ùå Error al conectar con la API: {e}")
        return None

# Interfaz de usuario
st.sidebar.header("üìÇ Seleccione una secci√≥n")
seccion_seleccionada = st.sidebar.selectbox("Secciones", list(secciones_urls.keys()))

if st.sidebar.button("üîç Analizar"):
    with st.spinner("üì• Obteniendo contenido..."):
        contenido = obtener_contenido(seccion_seleccionada)
    if contenido:
        st.subheader(f"üìë Contenido de la secci√≥n: {seccion_seleccionada}")
        st.text_area("üìù Texto a analizar", contenido, height=300)

        if st.button("‚úÖ Revisar Ortograf√≠a y Gram√°tica"):
            with st.spinner("üîÑ Analizando texto..."):
                informe = analizar_texto(contenido)
            if informe:
                st.subheader("üìÑ Informe de Revisi√≥n")
                st.write(informe)
